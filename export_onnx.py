import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
import yaml
import math
import types
import argparse
from learning.models.score_network import ScoreNetMultiPair
from learning.models.refine_network import RefineNet  

# ==============================================================================
# 1. å®šä¹‰æ‰‹åŠ¨å®ç°çš„ Attention ç±» (ç”¨äºæ›¿æ¢ nn.MultiheadAttention)
#    è¿™æ˜¯ä¸ºäº†è§£å†³ "Exporting the operator 'aten::_native_multi_head_attention'..." é”™è¯¯
# ==============================================================================
class ManualMultiheadAttention(nn.Module):
    def __init__(self, embed_dim, num_heads, bias=True, batch_first=True):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.batch_first = batch_first
        self.head_dim = embed_dim // num_heads
        assert self.head_dim * num_heads == self.embed_dim, "embed_dim must be divisible by num_heads"

        self.in_proj_weight = nn.Parameter(torch.empty(3 * embed_dim, embed_dim))
        if bias:
            self.in_proj_bias = nn.Parameter(torch.empty(3 * embed_dim))
        else:
            self.register_parameter('in_proj_bias', None)

        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)
        self._qkv_same_embed_dim = False 
        
    def forward(self, query, key, value, key_padding_mask=None, need_weights=True, attn_mask=None):
        is_batched = query.dim() == 3
        if self.batch_first and is_batched:
            query, key, value = query.transpose(0, 1), key.transpose(0, 1), value.transpose(0, 1)

        tgt_len, bsz, embed_dim = query.shape
        
        if torch.equal(query, key) and torch.equal(key, value):
            qkv = F.linear(query, self.in_proj_weight, self.in_proj_bias)
            qkv = qkv.view(tgt_len, bsz, 3, self.num_heads, self.head_dim)
            q, k, v = qkv.unbind(dim=2)
        else:
            w_q, w_k, w_v = self.in_proj_weight.chunk(3)
            if self.in_proj_bias is not None:
                b_q, b_k, b_v = self.in_proj_bias.chunk(3)
            else:
                b_q = b_k = b_v = None
            q = F.linear(query, w_q, b_q).view(tgt_len, bsz, self.num_heads, self.head_dim)
            k = F.linear(key, w_k, b_k).view(tgt_len, bsz, self.num_heads, self.head_dim)
            v = F.linear(value, w_v, b_v).view(tgt_len, bsz, self.num_heads, self.head_dim)

        q = q.permute(1, 2, 0, 3)
        k = k.permute(1, 2, 0, 3)
        v = v.permute(1, 2, 0, 3)

        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)
        if attn_mask is not None:
            scores += attn_mask
        attn_weights = F.softmax(scores, dim=-1)
        attn_output = torch.matmul(attn_weights, v)

        attn_output = attn_output.permute(2, 0, 1, 3).contiguous().view(tgt_len, bsz, embed_dim)
        attn_output = self.out_proj(attn_output)

        if self.batch_first and is_batched:
            attn_output = attn_output.transpose(0, 1)

        return attn_output, None

# ==============================================================================
# 2. å®šä¹‰ä¿®å¤ç‰ˆçš„ extract_feat å’Œ forward æ–¹æ³•
#    è¿™æ˜¯ä¸ºäº†è§£å†³ "aten::unflatten" å’Œ reshape é”™è¯¯
# ==============================================================================
def patched_extract_feat(self, A, B):
    """ æ›¿æ¢åŸæ¨¡å‹ä¸­çš„ extract_featï¼Œä¿®å¤ reshape/permute é—®é¢˜ """
    bs = A.shape[0]  # B*L
    x = torch.cat([A,B], dim=0)
    x = self.encoderA(x)
    a = x[:bs]
    b = x[bs:]
    ab = torch.cat((a,b), dim=1)
    ab = self.encoderAB(ab)
    
    # --- ä¿®å¤é€»è¾‘å¼€å§‹ ---
    # åŸä»£ç : ab = self.pos_embed(ab.reshape(bs, ab.shape[1], -1).permute(0,2,1))
    # ä¿®å¤ä¸º ONNX å‹å¥½çš„æ“ä½œ:
    B_L, C_prime, H_prime, W_prime = ab.shape
    ab_flat = ab.view(B_L, C_prime, H_prime * W_prime)
    ab_permuted = ab_flat.transpose(1, 2) # (B, HW, C)
    ab = self.pos_embed(ab_permuted)
    # --- ä¿®å¤é€»è¾‘ç»“æŸ ---

    ab, _ = self.att(ab, ab, ab)
    
    # ä¿®å¤æœ€åçš„ reshape
    # åŸä»£ç : return ab.mean(dim=1).reshape(bs,-1)
    return ab.mean(dim=1).view(bs, -1)

def patched_forward_score(self, A, B, L):
    output = {}
    # æ³¨æ„ï¼šåœ¨ ONNX å¯¼å‡ºæ—¶ï¼Œbs æ˜¯ç¬¦å·ï¼Œä¸èƒ½ç›´æ¥ç”¨äº reshape
    # ä½†æˆ‘ä»¬é€šè¿‡ view å’Œæ˜ç¡®çš„ç»´åº¦è®¡ç®—æ¥è§„é¿
    bs = A.shape[0] // L 
    feats = self.extract_feat(A, B)   #(B*L, C)
    
    # --- ä¿®å¤é€»è¾‘å¼€å§‹ ---
    # åŸä»£ç : x = feats.reshape(bs,L,-1)
    feat_dim = feats.shape[-1]
    x = feats.view(bs, L, feat_dim)
    x, _ = self.att_cross(x, x, x)
    output['score_logit'] = self.linear(x).view(bs, L)
    return output

# ==============================================================================
# 3. RefineNet ä¿®å¤è¡¥ä¸ (æ–°å¢)
# ==============================================================================
def patched_forward_refine(self, A, B):
    """ æ›¿æ¢ RefineNet ä¸­çš„ forwardï¼Œä¿®å¤ reshape/permute é—®é¢˜ """
    # åŸä»£ç : bs = len(A) -> åœ¨ ONNX ä¸­ len() å¯èƒ½æœ‰é—®é¢˜ï¼Œæ”¹ç”¨ shape[0]
    bs = A.shape[0]
    output = {}

    x = torch.cat([A,B], dim=0)
    x = self.encodeA(x)
    a = x[:bs]
    b = x[bs:]

    ab = torch.cat((a,b),1).contiguous()
    ab = self.encodeAB(ab)  #(B,C,H,W)

    # --- ä¿®å¤é€»è¾‘å¼€å§‹ ---
    # åŸä»£ç : ab = self.pos_embed(ab.reshape(bs, ab.shape[1], -1).permute(0,2,1))
    B_dim, C_prime, H_prime, W_prime = ab.shape
    ab_flat = ab.view(B_dim, C_prime, H_prime * W_prime)
    ab_permuted = ab_flat.transpose(1, 2) # (B, HW, C)
    ab = self.pos_embed(ab_permuted)
    # --- ä¿®å¤é€»è¾‘ç»“æŸ ---

    output['trans'] = self.trans_head(ab).mean(dim=1)
    output['rot'] = self.rot_head(ab).mean(dim=1)

    return output

# ==============================================================================
# 3. è¾…åŠ©å‡½æ•°ï¼šæ›¿æ¢æ¨¡å‹ä¸­çš„ Attention å±‚
# ==============================================================================
def replace_attention_layers(module):
    # é€’å½’æ›¿æ¢æ‰€æœ‰å­æ¨¡å—ä¸­çš„ MultiheadAttention
    for name, child in module.named_children():
        if isinstance(child, nn.MultiheadAttention):
            print(f"  -> æ­£åœ¨æ›¿æ¢å±‚: {name} (MultiheadAttention) ä¸º ManualMultiheadAttention")
            new_att = ManualMultiheadAttention(
                embed_dim=child.embed_dim, 
                num_heads=child.num_heads, 
                bias=(child.in_proj_bias is not None), 
                batch_first=child.batch_first
            )
            # å¤åˆ¶æƒé‡ (å‚æ•°åç§°å®Œå…¨ä¸€è‡´ï¼Œå¯ä»¥ç›´æ¥åŠ è½½)
            new_att.load_state_dict(child.state_dict())
            # æ›¿æ¢
            setattr(module, name, new_att)
        else:
            replace_attention_layers(child)

def load_config(weight_dir):
    config_path = os.path.join(weight_dir, 'config.yml')
    with open(config_path, 'r') as f:
        cfg = yaml.safe_load(f)
    return cfg

# --- æ–°å¢è¾…åŠ©ç±»ï¼šè§£å†³ RefineNet æ··ç”¨ cfg.key å’Œ cfg['key'] çš„é—®é¢˜ ---
class HybridConfig(dict):
    """ 
    ä¸€ä¸ªç®€å•çš„åŒ…è£…ç±»ï¼Œè®©å­—å…¸æ”¯æŒå±æ€§è®¿é—® (obj.key)ã€‚
    åŒæ—¶ä¿ç•™å­—å…¸çš„ä¸‹æ ‡è®¿é—® (obj['key']) èƒ½åŠ›ã€‚
    """
    def __getattr__(self, name):
        try:
            return self[name]
        except KeyError:
            raise AttributeError(f"'HybridConfig' object has no attribute '{name}'")
# -------------------------------------------------------------------

# ==============================================================================
# 5. å¯¼å‡ºå‡½æ•°
# ==============================================================================
SCORE_WEIGHT_DIR = 'weights/2024-01-11-20-02-45'
REFINE_WEIGHT_DIR = 'weights/2023-10-28-18-33-37' # <--- è¯·ç¡®è®¤æ­¤è·¯å¾„æ˜¯å¦æ­£ç¡®

def export_score_model():
    print(f"\n=== å¼€å§‹å¯¼å‡º Score æ¨¡å‹ (å†…å­˜çƒ­ä¿®è¡¥æ¨¡å¼) ===")
    weight_dir = SCORE_WEIGHT_DIR
    onnx_path = os.path.join(weight_dir, 'score_model.onnx')
    
    # 1. åŠ è½½é…ç½®
    cfg_dict = load_config(weight_dir)
    cfg = argparse.Namespace(**cfg_dict)
    c_in = getattr(cfg, 'c_in', 6)
    
    # 2. åˆå§‹åŒ–åŸå§‹æ¨¡å‹
    print("åˆå§‹åŒ–åŸå§‹æ¨¡å‹...")
    model = ScoreNetMultiPair(cfg=cfg, c_in=c_in)
    
    # 3. åŠ è½½æƒé‡
    ckpt_path = os.path.join(weight_dir, 'model_best.pth')
    print(f"åŠ è½½æƒé‡: {ckpt_path}")
    ckpt = torch.load(ckpt_path)
    if 'model' in ckpt:
        ckpt = ckpt['model']
    model.load_state_dict(ckpt)
    
    # 4. ã€å…³é”®æ­¥éª¤ã€‘åœ¨å†…å­˜ä¸­ä¿®è¡¥æ¨¡å‹
    print("æ­£åœ¨åº”ç”¨å†…å­˜è¡¥ä¸ä»¥ä¿®å¤ ONNX å…¼å®¹æ€§...")
    
    # 4.1 æ›¿æ¢ Attention å±‚
    replace_attention_layers(model)
    
    # 4.2 æ›¿æ¢æ–¹æ³• (Method Swapping)
    # ä½¿ç”¨ types.MethodType å°†æˆ‘ä»¬å®šä¹‰çš„ä¿®å¤ç‰ˆå‡½æ•°ç»‘å®šåˆ°æ¨¡å‹å®ä¾‹ä¸Š
    model.extract_feat = types.MethodType(patched_extract_feat, model)
    model.forward = types.MethodType(patched_forward_score, model)
    
    model.eval()
    model.cuda()

    # 5. åˆ›å»ºè™šæ‹Ÿè¾“å…¥
    bs = 1
    L = 3
    h, w = getattr(cfg, 'input_resize', [160, 160])
    dummy_input_A = torch.randn(bs * L, c_in, h, w).cuda()
    dummy_input_B = torch.randn(bs * L, c_in, h, w).cuda()
    
    print(f"è¾“å…¥å½¢çŠ¶: A={dummy_input_A.shape}, B={dummy_input_B.shape}, L={L}")

    # 6. å¯¼å‡º ONNX
    print(f"æ­£åœ¨å¯¼å‡ºåˆ°: {onnx_path}")
    torch.onnx.export(
        model,
        (dummy_input_A, dummy_input_B, L),
        onnx_path,
        input_names=['input_A', 'input_B', 'L'],
        output_names=['score_logit'],
        dynamic_axes={
            'input_A': {0: 'batch_times_L'},
            'input_B': {0: 'batch_times_L'},
            'score_logit': {0: 'batch_size'}
        },
        opset_version=13,
        do_constant_folding=True
    )
    print(f"âœ… Score æ¨¡å‹å¯¼å‡ºæˆåŠŸï¼è·¯å¾„: {onnx_path}")

def export_refine_model():
    print(f"\n=== å¼€å§‹å¯¼å‡º Refine æ¨¡å‹ (å†…å­˜çƒ­ä¿®è¡¥æ¨¡å¼) ===")
    weight_dir = REFINE_WEIGHT_DIR
    onnx_path = os.path.join(weight_dir, 'refine_model.onnx')
    
    if not os.path.exists(weight_dir):
        print(f"âŒ é”™è¯¯: Refine æƒé‡ç›®å½•ä¸å­˜åœ¨: {weight_dir}")
        return

    cfg_dict = load_config(weight_dir)
    # cfg = argparse.Namespace(**cfg_dict)
    # c_in = getattr(cfg, 'c_in', 6)
    cfg = HybridConfig(cfg_dict)
    c_in = cfg_dict.get('c_in', 6)
    
    print("åˆå§‹åŒ–åŸå§‹æ¨¡å‹...")
    model = RefineNet(cfg=cfg, c_in=c_in)
    
    ckpt_path = os.path.join(weight_dir, 'model_best.pth')
    print(f"åŠ è½½æƒé‡: {ckpt_path}")
    ckpt = torch.load(ckpt_path)
    if 'model' in ckpt:
        ckpt = ckpt['model']
    model.load_state_dict(ckpt)
    
    print("æ­£åœ¨åº”ç”¨å†…å­˜è¡¥ä¸...")
    # 1. æ›¿æ¢ Attention å±‚ (RefineNet ä½¿ç”¨äº† TransformerEncoderLayerï¼Œå†…éƒ¨æœ‰ MultiheadAttention)
    replace_attention_layers(model)
    
    # 2. æ›¿æ¢ forward æ–¹æ³•
    model.forward = types.MethodType(patched_forward_refine, model)
    
    model.eval()
    model.cuda()

    bs = 1
    h, w = cfg_dict.get('input_resize', [160, 160])
    dummy_input_A = torch.randn(bs, c_in, h, w).cuda()
    dummy_input_B = torch.randn(bs, c_in, h, w).cuda()
    
    print(f"è¾“å…¥å½¢çŠ¶: A={dummy_input_A.shape}, B={dummy_input_B.shape}")
    print(f"æ­£åœ¨å¯¼å‡ºåˆ°: {onnx_path}")
    
    torch.onnx.export(
        model,
        (dummy_input_A, dummy_input_B),
        onnx_path,
        input_names=['input_A', 'input_B'],
        output_names=['trans', 'rot'],
        dynamic_axes={
            'input_A': {0: 'batch_size'},
            'input_B': {0: 'batch_size'},
            'trans': {0: 'batch_size'},
            'rot': {0: 'batch_size'}
        },
        opset_version=13,
        do_constant_folding=True
    )
    print(f"âœ… Refine æ¨¡å‹å¯¼å‡ºæˆåŠŸï¼è·¯å¾„: {onnx_path}")

if __name__ == "__main__":
    if not os.path.exists(SCORE_WEIGHT_DIR):
        print(f"é”™è¯¯: æƒé‡ç›®å½•ä¸å­˜åœ¨: {SCORE_WEIGHT_DIR}")
        sys.exit(1)

    try:
        export_score_model()
        export_refine_model()
        print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹å¯¼å‡ºå®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()